import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from io import BytesIO
import re

# -----------------------------
# H√†m l·∫•y d·ªØ li·ªáu theo nh√≥m vƒÉn b·∫£n
# -----------------------------
def scrape_masothue(pages=1):
    base_url = ("https://masothue.com/tra-cuu-ma-so-thue-theo-loai-hinh-doanh-nghiep/"
                "ho-kinh-doanh-ca-the-20?page=")
    results = []

    for page in range(1, pages + 1):
        url = base_url + str(page)
        try:
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')

            # L·∫•y ph·∫ßn danh s√°ch h·ªô KD
            section = soup.find("div", class_="tax-listing")
            if not section:
                continue

            # Tr√≠ch to√†n b·ªô ƒëo·∫°n text, b·ªè c√°c ƒëo·∫°n kh√¥ng li√™n quan
            raw_text = section.get_text(separator="\n").strip()

            # T√°ch t·ª´ng d√≤ng
            lines = [line.strip() for line in raw_text.split("\n") if line.strip()]
            i = 0
            while i < len(lines) - 3:
                name = lines[i]
                mst_line = lines[i+1]
                nguoidd_line = lines[i+2]
                diachi = lines[i+3]

                # X√°c ƒë·ªãnh c√≥ ph·∫£i ƒë√∫ng m·∫´u kh√¥ng
                if mst_line.startswith("M√£ s·ªë thu·∫ø:") and nguoidd_line.startswith("Ng∆∞·ªùi ƒë·∫°i di·ªán:"):
                    mst = mst_line.replace("M√£ s·ªë thu·∫ø:", "").strip()
                    nguoidd = nguoidd_line.replace("Ng∆∞·ªùi ƒë·∫°i di·ªán:", "").strip()
                    results.append({
                        "T√™n h·ªô kinh doanh": name,
                        "M√£ s·ªë thu·∫ø": mst,
                        "Ng∆∞·ªùi ƒë·∫°i di·ªán": nguoidd,
                        "ƒê·ªãa ch·ªâ": diachi
                    })
                    i += 4
                else:
                    i += 1

        except Exception as e:
            st.error(f"L·ªói khi t·∫£i trang {page}: {e}")

    return results

# -----------------------------
# Xu·∫•t Excel
# -----------------------------
@st.cache_data
def convert_df_to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='HoKD')
    return output.getvalue()

# -----------------------------
# Giao di·ªán ch√≠nh
# -----------------------------
st.set_page_config(page_title="Tra c·ª©u h·ªô KD c√° th·ªÉ", layout="wide")
st.title("üìã Tra c·ª©u h·ªô kinh doanh c√° th·ªÉ t·ª´ masothue.com")

pages = st.slider("üî¢ Ch·ªçn s·ªë trang mu·ªën t·∫£i", min_value=1, max_value=10, value=3)

if st.button("üöÄ T·∫£i d·ªØ li·ªáu"):
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
        data = scrape_masothue(pages)
        df = pd.DataFrame(data)

        if df.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu. C√≥ th·ªÉ trang ƒëang ch·∫∑n ho·∫∑c ƒë·ªïi c·∫•u tr√∫c.")
        else:
            st.success(f"‚úÖ ƒê√£ t·∫£i {len(df)} d√≤ng t·ª´ {pages} trang.")
            st.dataframe(df, use_container_width=True)

            excel_data = convert_df_to_excel(df)

            st.download_button(
                label="üì• T·∫£i v·ªÅ Excel",
                data=excel_data,
                file_name="ho_kinh_doanh.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
