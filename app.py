import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from io import BytesIO

# -----------------------------
# H√†m l·∫•y d·ªØ li·ªáu t·ª´ masothue.com theo HTML m·ªõi
# -----------------------------
def scrape_masothue(pages=1):
    base_url = ("https://masothue.com/tra-cuu-ma-so-thue-theo-loai-hinh-doanh-nghiep/"
                "ho-kinh-doanh-ca-the-20?page=")
    results = []

    for page in range(1, pages + 1):
        url = base_url + str(page)
        try:
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')

            # M·ªói h·ªô KD hi·ªÉn th·ªã trong th·∫ª <div data-prefetch>
            listings = soup.select("div.tax-listing > div[data-prefetch]")

            for listing in listings:
                # T√™n h·ªô KD
                name_tag = listing.select_one("h3 > a")
                name = name_tag.get_text(strip=True) if name_tag else ""

                # ƒê·ªãa ch·ªâ
                address_tag = listing.select_one("address")
                address = address_tag.get_text(strip=True) if address_tag else ""

                # M√£ s·ªë thu·∫ø & Ng∆∞·ªùi ƒë·∫°i di·ªán
                divs = listing.find_all("div")
                mst = ""
                nguoidd = ""
                for div in divs:
                    txt = div.get_text(strip=True)
                    if "M√£ s·ªë thu·∫ø:" in txt:
                        mst = txt.replace("M√£ s·ªë thu·∫ø:", "").strip()
                    elif "Ng∆∞·ªùi ƒë·∫°i di·ªán:" in txt:
                        nguoidd = txt.replace("Ng∆∞·ªùi ƒë·∫°i di·ªán:", "").strip()

                results.append({
                    "T√™n h·ªô kinh doanh": name,
                    "M√£ s·ªë thu·∫ø": mst,
                    "Ng∆∞·ªùi ƒë·∫°i di·ªán": nguoidd,
                    "ƒê·ªãa ch·ªâ": address
                })

        except Exception as e:
            st.error(f"L·ªói khi t·∫£i trang {page}: {e}")

    return results

# -----------------------------
# Chuy·ªÉn DataFrame th√†nh file Excel (RAM)
# -----------------------------
@st.cache_data
def convert_df_to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='HoKD')
    return output.getvalue()

# -----------------------------
# Giao di·ªán ch√≠nh
# -----------------------------
st.set_page_config(page_title="Tra c·ª©u h·ªô KD c√° th·ªÉ", layout="wide")
st.title("üìã Tra c·ª©u h·ªô kinh doanh c√° th·ªÉ t·ª´ masothue.com")

pages = st.slider("üî¢ Ch·ªçn s·ªë trang mu·ªën t·∫£i", min_value=1, max_value=10, value=3)

if st.button("üöÄ T·∫£i d·ªØ li·ªáu"):
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
        data = scrape_masothue(pages)
        df = pd.DataFrame(data)

        if df.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu. C√≥ th·ªÉ ƒëang b·ªã ch·∫∑n ho·∫∑c c·∫•u tr√∫c web thay ƒë·ªïi.")
        else:
            st.success(f"‚úÖ ƒê√£ t·∫£i {len(df)} d√≤ng t·ª´ {pages} trang.")

            st.dataframe(df, use_container_width=True)

            excel_data = convert_df_to_excel(df)

            st.download_button(
                label="üì• T·∫£i v·ªÅ Excel",
                data=excel_data,
                file_name="ho_kinh_doanh.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
